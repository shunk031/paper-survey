<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="https://shunk031.github.io/paper-survey/feed.xml" rel="self" type="application/atom+xml" /><link href="https://shunk031.github.io/paper-survey/" rel="alternate" type="text/html" /><updated>2019-07-27T15:32:30+00:00</updated><id>https://shunk031.github.io/paper-survey/feed.xml</id><title type="html">Paper Survey</title><subtitle>Survey of previous research and related works on machine learning (especially Deep Learning) in Japanese
</subtitle><entry><title type="html">DropAttention: A Regularization Method for Fully Connected Self Attention-Networks</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/DropAttention-A-Regularization-Method-for-Fully-Connected-Self-Attention-Networks" rel="alternate" type="text/html" title="DropAttention: A Regularization Method for Fully Connected Self Attention-Networks" /><published>2019-07-27T00:00:00+00:00</published><updated>2019-07-27T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/DropAttention-A-Regularization-Method-for-Fully-Connected-Self-Attention-Networks</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/DropAttention-A-Regularization-Method-for-Fully-Connected-Self-Attention-Networks">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;全結合からなる self-attention 層に対して dropout を行う DropAttention を用いて過学習抑制し汎化性能向上を確認した。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;Dropout は全結合層に対して確率的にノード落とすことで過学習を抑えることができる。
こうした手法は recurrent neural network (RNN) や convolutional neural network (CNN) にも応用されており、それぞれパフォーマンスの向上が確認されている。&lt;/p&gt;

&lt;p&gt;本研究では dropout 手法を全結合からなる self-attention に対して適用する DropAttention を提案し、汎化性能向上を確認している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/DropAttention-A-Regularization-Method-for-Fully-Connected-Self-Attention-Networks/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;dropattention&quot;&gt;DropAttention&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;複数種類の dropout 手法を比較
    &lt;ul&gt;
      &lt;li&gt;DropAttention(c)
        &lt;ul&gt;
          &lt;li&gt;列ベースで dropout する。先行研究の Dropout と同様の振る舞い。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;DropAttention(e)
        &lt;ul&gt;
          &lt;li&gt;要素ベースで dropout する。先行研究の DropConnect と同賞の振る舞い。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;これらの DropAttention にはハイパーパラメータとして dropout 率 &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; と drop 対象となる連続した範囲を示すウィンドウサイズ &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; の設定が必要である。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dropout 後のリスケーリング処理
    &lt;ul&gt;
      &lt;li&gt;Attention に対して dropout した後に再度総和を取ると 1 となるようにリスケーリングを行う&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;テキスト分類、系列ラベリング、テキスト含意認識、機械翻訳の 4 つのタスクに対して、DropAttention(c)および DropAttention(e)の効果確認を行っている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;DropAttention(c)および(e)のハイパーパラメータについて
    &lt;ul&gt;
      &lt;li&gt;DropAttention(c)の場合 dropout 率は大きく、小さいウィンドウサイズを用いるのが良い&lt;/li&gt;
      &lt;li&gt;DropAttention(e)の場合 dropout 率は小さく、大きいウィンドウサイズを用いるのが良い&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;先行研究である dropout も適用後にリスケーリング処理を行うが、同様の処理を DropAttention に適用すると性能が悪くなることが確認された。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Dropout 関連の論文がまとまっているので参考になる&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/DropAttention-A-Regularization-Method-for-Fully-Connected-Self-Attention-Networks/table1.png&quot; alt=&quot;Table 1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1907.11065&quot;&gt;Lin Zehui, Pengfei Liu, Luyao Huang, Jie Fu, Junkun Chen, Xipeng Qiu, Xuanjing Huang. DropAttention: A Regularization Method for Fully-Connected Self-Attention Networks. arXiv:1907.11065, 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">From Small-scale to Large-scale Text Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/From-Small-scale-to-Large-scale-Text-Classification" rel="alternate" type="text/html" title="From Small-scale to Large-scale Text Classification" /><published>2019-07-09T00:00:00+00:00</published><updated>2019-07-09T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/From-Small-scale-to-Large-scale-Text-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/From-Small-scale-to-Large-scale-Text-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;カテゴリ数が非常に多いテキスト分類と比較的カテゴリ数の少ないテキスト分類を同時に行うマルチタスクなモデルアーキテクチャを提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;テキスト分類においてカテゴリ数が非常に多い &lt;code class=&quot;highlighter-rouge&quot;&gt;large-scale&lt;/code&gt; な問題設定と、比較的カテゴリ数の少ない &lt;code class=&quot;highlighter-rouge&quot;&gt;small-scale&lt;/code&gt; な問題設定がある。&lt;/p&gt;

&lt;p&gt;Web 検索のパーソナライズやレコメンドシステムなど、カテゴリ数が非常に多いテキスト分類は学習時に各カテゴリを捉えられるよう大規模なデータセットが必要である。&lt;/p&gt;

&lt;p&gt;先行研究ではカテゴリ数の多いデータに対する研究はあるが、これらの手法は単語間の意味的類似性の重要度を考慮せずに、用語に対する重み付け手法のみを考慮している。
また、十分なデータ数が確保できない場合に対してマルチタスク学習を適用する研究はあるが、カテゴリ数の非常に多い大規模なテキスト分類に対する研究はとても少ない。&lt;/p&gt;

&lt;p&gt;本研究ではカテゴリ数が非常に大きいものと比較的小さいもののテキスト分類のために、タスク間で有効な特徴を共有するマルチタスク学習と、
各タスクに有効な特徴を選択する gate 構造 を導入した convolutional neural network (CNN) ベースのネットワークを提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/From-Small-scale-to-Large-scale-Text-Classification/figure1.png&quot; width=&quot;600px&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;カテゴリ数の多い大規模なテキスト分類に対するマルチタスク学習&quot;&gt;カテゴリ数の多い大規模なテキスト分類に対するマルチタスク学習&lt;/h3&gt;
&lt;h4 id=&quot;shared-layer-と-private-layer&quot;&gt;Shared layer と Private layer&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;タスク間で不変な特徴とタスクで独立な特徴をそれぞれ捉えるモデルアーキテクチャ
    &lt;ul&gt;
      &lt;li&gt;Shared Layer
        &lt;ul&gt;
          &lt;li&gt;各タスクに対して共有の畳込み+プーリングを用いて、タスク間で共通の特徴を学習可能&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Private Layer
    &lt;ul&gt;
      &lt;li&gt;タスク固有の畳み込み+プーリングを用いて、タスク独立な特徴を学習可能&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;gate-構造&quot;&gt;Gate 構造&lt;/h4&gt;
&lt;p&gt;小規模なテキスト分類タスクから大規模テキスト分類タスクへ効果的な特徴を選択する。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf{g} = \sigma(\textbf{W}_{\textrm{small} \to \textrm{large}} \textbf{z}_{\textrm{small}} + \textbf{b}_{\textrm{small} \to \textrm{large}})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Large-scale&lt;/code&gt; テキスト分類タスクにおいて、ゲート &lt;script type=&quot;math/tex&quot;&gt;{\bf g}&lt;/script&gt; を用いて最終的な特徴量を得る
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf{z}'_{\textrm{large}} = \textbf{z}_{\textrm{large}} + \textbf{z}_{\textrm{share}} + \textbf{g} \odot \textbf{z}_{\textrm{small}}&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Small-scale&lt;/code&gt; テキスト分類タスクにおいては以下となる
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf{z}'_{\textrm{small}} = \textbf{z}_{\textrm{small}} + \textbf{z}_{\textrm{share}}&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;モデルの学習&quot;&gt;モデルの学習&lt;/h3&gt;
&lt;h4 id=&quot;joint-traning&quot;&gt;Joint Traning&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;ランダムにタスクを選択する (&lt;code class=&quot;highlighter-rouge&quot;&gt;large-scale&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;small-scale&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;選択したタスクに沿った学習データを選択する&lt;/li&gt;
  &lt;li&gt;これら学習データをもとに勾配降下法でパラメータを更新する&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;oversampling&quot;&gt;Oversampling&lt;/h4&gt;
&lt;p&gt;カテゴリ数の多いデータセットの場合、カテゴリごとで分布に差があるため、少ないカテゴリをオーバーサンプリングして対処する。&lt;/p&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;
&lt;h3 id=&quot;データセット&quot;&gt;データセット&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Open Directory Project (ODP)
    &lt;ul&gt;
      &lt;li&gt;大規模な木構造の web ページディレクトリ
 	- 15 階層に及び、前処理後には 3000 近くのカテゴリが含まれている。
        &lt;ul&gt;
          &lt;li&gt;大分類と小分類が含まれている。
            &lt;ul&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Top/Sports&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Top/Health&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Top/Computers&lt;/code&gt;&lt;/li&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Top/Sports/Baseball/Major_League/Teams/Los_Angles_Dogders/News_and_Media&lt;/code&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;学習データとして 23,000 ページを対象
 	  - &lt;code class=&quot;highlighter-rouge&quot;&gt;Smal-scale&lt;/code&gt; テキスト分類タスク用にトップレベルの 13 カテゴリを使用&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;New York Times (NYT)
    &lt;ul&gt;
      &lt;li&gt;ODP の追加テストデータとして、new york times の記事から &lt;code class=&quot;highlighter-rouge&quot;&gt;art&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;business&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;food&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;health&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;politics&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;sports&lt;/code&gt; なカテゴリをランダムに取得して評価に使用した。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;評価指標&quot;&gt;評価指標&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;F1 score をベースに使用
    &lt;ul&gt;
      &lt;li&gt;Micro-averaging (Mi-) F1 score
        &lt;ul&gt;
          &lt;li&gt;テストデータ全体の F1 スコア
            &lt;ul&gt;
              &lt;li&gt;データ数の多いカテゴリを正確に当てられているか&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Macro-averaging (Ma-) F1 score
        &lt;ul&gt;
          &lt;li&gt;各カテゴリ数に応じた F1 スコア
 	  - データ数の少ないカテゴリを正確に当てられているか&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;NYT データセットに対しては precision@k を使用
    &lt;ul&gt;
      &lt;li&gt;記事に対してアノテータが ODP のカテゴリとマッチするように&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ベースラインモデルとの比較&quot;&gt;ベースラインモデルとの比較&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;ベースモデル
    &lt;ul&gt;
      &lt;li&gt;MC (Merge-Centroid)&lt;/li&gt;
      &lt;li&gt;CNN&lt;/li&gt;
      &lt;li&gt;LSTM&lt;/li&gt;
      &lt;li&gt;BiLSTM&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;単語ベクトル系
    &lt;ul&gt;
      &lt;li&gt;PV&lt;/li&gt;
      &lt;li&gt;fastText&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;マルチタスク系
    &lt;ul&gt;
      &lt;li&gt;MT-DNN&lt;/li&gt;
      &lt;li&gt;MT-CNN&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;提案手法
    &lt;ul&gt;
      &lt;li&gt;SP-LSTM
        &lt;ul&gt;
          &lt;li&gt;Share layer + Private layer w/o Gate&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;SPG-CNN
        &lt;ul&gt;
          &lt;li&gt;Share layer + Private layer w/ Gate&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;
&lt;h3 id=&quot;gate-構造の比較&quot;&gt;Gate 構造の比較&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;大規模分類タスクと小規模分類タスク間の gate 方向について
    &lt;ul&gt;
      &lt;li&gt;large → small 方向より、small → large 方向のほうが良かった&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;異なる事前学習済み単語ベクトルを使用したときの精度比較&quot;&gt;異なる事前学習済み単語ベクトルを使用したときの精度比較&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;word2vec や GloVe より fastText を用いたほうがよかった
    &lt;ul&gt;
      &lt;li&gt;fastText は OOV に強い&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;odp-データセットに対する精度比較&quot;&gt;ODP データセットに対する精度比較&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Large-scale&lt;/code&gt; テキスト分類タスクでは提案手法 SPG-CNN が outperform&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Small-scale&lt;/code&gt; テキスト分類タスクにおいては share layer + private layer のある LSTM が outperform
    &lt;ul&gt;
      &lt;li&gt;データが十分にあってカテゴリ間の分布が均衡なものは CNN より LSTM が強い傾向は先行研究でも確認されている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nyt-データセットに対する精度比較&quot;&gt;NYT データセットに対する精度比較&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;提案手法の SPG-CNN が outperform
    &lt;ul&gt;
      &lt;li&gt;そのほかのマルチタスクモデルもシングルタスクモデルよりも良い結果&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;MC (Merge-Centroid) について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2529997&quot;&gt;Lee, Jung-Hyun, et al. “Semantic contextual advertising based on the open directory project.” ACM Transactions on the Web (TWEB) 7.4 (2013): 24.p&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3313563&quot;&gt;Kim, Kang-Min, et al. “From Small-scale to Large-scale Text Classification.” The World Wide Web Conference. ACM, 2019.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Content-Based Citation Recommendation</title><link href="https://shunk031.github.io/paper-survey/summary/others/Content-Based-Citation-Recommendation" rel="alternate" type="text/html" title="Content-Based Citation Recommendation" /><published>2019-06-25T00:00:00+00:00</published><updated>2019-06-25T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/others/Content-Based-Citation-Recommendation</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/others/Content-Based-Citation-Recommendation">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;
&lt;p&gt;メタデータに依存しない論文内容に基づいた、学術論文の草案に対する引用文献の推薦システムの提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;
&lt;p&gt;既存の引用文献レコメンドシステムは著者の名前や出版社・学会名等のメタデータに依存している場合が多かった。
こうしたメタデータはレビュー時であったり草案時には利用が難しい。&lt;/p&gt;

&lt;p&gt;本研究では既存の研究と異なり、論文内容に基づいて引用候補を識別するために使用したベクトルと同じ空間に埋め込み、
再学習が不要なモデルの構築が可能となる。
また計算の効率がよく、学習時・予測時にスケーラブルなモデルである。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/others/Content-Based-Citation-Recommendation/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;phase-1---candidate-selection-nnselect&quot;&gt;Phase 1 - Candidate Selection (NNSelect)&lt;/h3&gt;
&lt;p&gt;学習させた文書の埋込モデルを使って、クエリ論文に近い論文を推薦候補として取得する。&lt;/p&gt;

&lt;h4 id=&quot;文書の埋め込みモデル&quot;&gt;文書の埋め込みモデル&lt;/h4&gt;
&lt;p&gt;論文のタイトルとアブストラクトを用いて文書埋め込みを計算する。
タイトルとアブストラクトをそれぞれ Bag-of-Words 形式の表現にした後に重み付け和を取ったものを使用した。
これら重み付けタイトル・アブストラクト表現に対してそれぞれ学習可能なパラメータを用いた重み付け和を計算し、文書の埋め込み表現を取得する。&lt;/p&gt;

&lt;h4 id=&quot;モデルの学習&quot;&gt;モデルの学習&lt;/h4&gt;
&lt;p&gt;クエリ論文 &lt;script type=&quot;math/tex&quot;&gt;d_q&lt;/script&gt; と引用されている論文 &lt;script type=&quot;math/tex&quot;&gt;d^{+}&lt;/script&gt; 、引用されていない文書 &lt;script type=&quot;math/tex&quot;&gt;d^{-}&lt;/script&gt; の triplet を用いて学習を行う。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm loss} = \max{( \alpha + s(d_q, d^{+}) - s(d_q, d^{+}), 0)}&lt;/script&gt;

&lt;p&gt;このとき &lt;script type=&quot;math/tex&quot;&gt;s(d_i, d_j)&lt;/script&gt; は文書埋め込みのコサイン類似度 &lt;script type=&quot;math/tex&quot;&gt;{\rm cos\-sim} ({\bf e}_{d_i}, {\bf e}_{d}_j_)&lt;/script&gt; として定義される。&lt;/p&gt;

&lt;h4 id=&quot;負例選択&quot;&gt;負例選択&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Random
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;d_q&lt;/script&gt; に引用されていない論文をランダムに選択&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Negative nearest neighbors
    &lt;ul&gt;
      &lt;li&gt;埋め込み空間上で&lt;script type=&quot;math/tex&quot;&gt;d_q&lt;/script&gt;に近いが引用されていない論文を選択&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Citation-of-citation
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;d_q&lt;/script&gt;には直接引用されていないが、&lt;script type=&quot;math/tex&quot;&gt;d_q&lt;/script&gt;が引用している論文に引用されている論文&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;phase-2---reranking-candidates-nnrank&quot;&gt;Phase 2 - Reranking Candidates (NNRank)&lt;/h3&gt;
&lt;p&gt;推薦候補論文はクエリ論文に対して予測確率に基づいてソートされ、トップの論文が候補として提示する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/others/Content-Based-Citation-Recommendation/figure2.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;入力特徴&quot;&gt;入力特徴&lt;/h4&gt;
&lt;p&gt;提案モデルでは論文のタイトルやアブストラクトのみで、メタデータを使用せずとも先行研究を超える性能を発揮するが、より性能を向上させるために以下の特徴を考慮した。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;タイトル&lt;/li&gt;
  &lt;li&gt;アブストラクト&lt;/li&gt;
  &lt;li&gt;著者名&lt;/li&gt;
  &lt;li&gt;出版社名 (学会名)&lt;/li&gt;
  &lt;li&gt;キーワード&lt;/li&gt;
  &lt;li&gt;クエリ論文と候補論文とのテキストの交差特徴&lt;/li&gt;
  &lt;li&gt;論文被引用数&lt;/li&gt;
  &lt;li&gt;テキストの埋め込み表現のコサイン類似度&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;モデルのアーキテクチャ&quot;&gt;モデルのアーキテクチャ&lt;/h4&gt;
&lt;h4 id=&quot;モデルの学習-1&quot;&gt;モデルの学習&lt;/h4&gt;
&lt;p&gt;入力特徴を concat したものをフィードフォワードニューラルネットワークに入力する。
損失関数として&lt;code class=&quot;highlighter-rouge&quot;&gt;NNSelect&lt;/code&gt;と同様に&lt;code class=&quot;highlighter-rouge&quot;&gt;triplet loss&lt;/code&gt;を使用する。
ここでは &lt;script type=&quot;math/tex&quot;&gt;s(d_i, d_j)&lt;/script&gt; としてフィードフォワードニューラルネットワークの出力を sigmoid の通した値を使用する。
テスト時にはこの &lt;script type=&quot;math/tex&quot;&gt;s(d_i, d_j)&lt;/script&gt; の値が一番高いものを推薦候補として使用する。&lt;/p&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;
&lt;p&gt;論文引用推薦の評価に用いられる DBLP、PubMed データセットを使用した。
また新たに &lt;code class=&quot;highlighter-rouge&quot;&gt;OpenCorpus&lt;/code&gt; という 700 万件程度のコンピュータサイエンスやニューロサイエンスの科学論文を集めたデータセットを構築し、モデルの評価に使用した。&lt;/p&gt;

&lt;p&gt;ベースラインとして先行研究の Cluscite と BM25 に対して提案手法の比較を行った。
評価指標として &lt;code class=&quot;highlighter-rouge&quot;&gt;Mean Reciprocal Rank (MRR)&lt;/code&gt; と &lt;code class=&quot;highlighter-rouge&quot;&gt;F1@20&lt;/code&gt; を使用した。&lt;/p&gt;

&lt;p&gt;候補論文を &lt;code class=&quot;highlighter-rouge&quot;&gt;NNSelect&lt;/code&gt; で探索するに当たり、近傍探索アルゴリズムとして &lt;code class=&quot;highlighter-rouge&quot;&gt;Annoy&lt;/code&gt; を使用した。
また提案手法のハイパーパラメータを &lt;code class=&quot;highlighter-rouge&quot;&gt;hyperopt&lt;/code&gt; で最適化した。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;
&lt;h3 id=&quot;負例選択について&quot;&gt;負例選択について&lt;/h3&gt;
&lt;p&gt;モデルの学習時に埋め込み空間上でクエリ論文に近いが引用されていない論文を負例として使用することで、効率的に学習することが分かった。&lt;/p&gt;

&lt;h3 id=&quot;有効な特徴について&quot;&gt;有効な特徴について&lt;/h3&gt;
&lt;p&gt;各特徴量の貢献度合いを見ると、テキストの交差特徴が他の特徴量よりも予測に貢献していることが分かった。&lt;/p&gt;

&lt;h3 id=&quot;出版社学会名に対する頑健性について&quot;&gt;出版社・学会名に対する頑健性について&lt;/h3&gt;
&lt;p&gt;出版社や学会のランクに対してロバストなモデルの構築が可能であることが分かった。&lt;/p&gt;

&lt;h3 id=&quot;テキスト特徴のエンコーディングについて&quot;&gt;テキスト特徴のエンコーディングについて&lt;/h3&gt;
&lt;p&gt;CNN や RNN をテキストのエンコーディングに使用したが、それほど性能の向上には寄与しなかった。
本研究で使用している BoW ベースの文書埋め込みを使用することで計算量を小さくスケーラブルなモデルになる。&lt;/p&gt;

&lt;h3 id=&quot;クエリ論文に対する近傍の数について&quot;&gt;クエリ論文に対する近傍の数について&lt;/h3&gt;
&lt;p&gt;実験結果から 5-近傍のときに評価指標が最大となることがわかった。&lt;/p&gt;

&lt;h3 id=&quot;自己引用のバイアスについて&quot;&gt;自己引用のバイアスについて&lt;/h3&gt;
&lt;p&gt;メタデータ（例えば著者）で訓練されたモデルは、自己引用や他の有名な著者に偏っている可能性があると仮定し、
メタデータの有無でそれぞれ &lt;code class=&quot;highlighter-rouge&quot;&gt;NNRank&lt;/code&gt; モデルを学習させる実験を行った。
メタデータを使って訓練されたモデルは、クエリ論文の著者の 1 人によって作成された論文を上位に推薦する傾向を確認した。&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Cuscite について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2623630&quot;&gt;Ren, Xiang, et al. “Cluscite: Effective citation recommendation by information network-based clustering.” Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/papers/N/N18/N18-1022/&quot;&gt;Bhagavatula, Chandra, et al. “Content-Based Citation Recommendation.” Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). 2018.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？ メタデータに依存しない論文内容に基づいた、学術論文の草案に対する引用文献の推薦システムの提案。</summary></entry><entry><title type="html">Class-Balanced Loss Based on Effective Number of Samples</title><link href="https://shunk031.github.io/paper-survey/summary/cv/Class-Balanced-Loss-Based-on-Effective-Number-of-Samples" rel="alternate" type="text/html" title="Class-Balanced Loss Based on Effective Number of Samples" /><published>2019-05-25T00:00:00+00:00</published><updated>2019-05-25T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/cv/Class-Balanced-Loss-Based-on-Effective-Number-of-Samples</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/cv/Class-Balanced-Loss-Based-on-Effective-Number-of-Samples">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;Long-tail な不均衡データに対して、各クラス数の分布を適切に考慮した class-balanced loss を提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Class-Balanced-Loss-Based-on-Effective-Number-of-Samples/figure1.png&quot; width=&quot;400px&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;実世界のデータセットは long-tail な分布を持つ不均衡データであることが多い。
こうした不均衡データに対して、先行研究では主に &lt;code class=&quot;highlighter-rouge&quot;&gt;re-sampling&lt;/code&gt; と &lt;code class=&quot;highlighter-rouge&quot;&gt;cost-sensitive learning&lt;/code&gt; の観点から解決が図られてきた。
&lt;code class=&quot;highlighter-rouge&quot;&gt;Re-sampling&lt;/code&gt; における over-sampling では学習時に重複したデータを学習して過学習を引き起こしたり、under-sampling では学習に重要なデータを適切にサンプリングして学習することが難しい。
そこで深層学習の文脈では損失関数に重み付けを行う &lt;code class=&quot;highlighter-rouge&quot;&gt;cost-sensitive learning&lt;/code&gt; を採用する場合が多いが、こうした手法は実世界の long-tail な分布を持つ不均衡データに対してパフォーマンスが低下してしまう場合が多い。
本研究では long-tail な不均衡データに対して、対象となるデータ数に効果的な &lt;code class=&quot;highlighter-rouge&quot;&gt;class-balanced loss&lt;/code&gt; を提案し、
一般的に広く使われている softmax cross-entropy や sigmoid cross-entropy、focal loss などに適用し効果の検証を行っている。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;h3 id=&quot;class-balanced-loss&quot;&gt;Class-balanced loss&lt;/h3&gt;

&lt;p&gt;各クラス数に反比例する重み係数を導入することによって、long-tail な不均衡データに対しても効率的に学習するよう損失関数を定義した。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm CB}({\bf p}, y) = \frac{1}{E_{n_y}} \mathcal{L}({\bf p}, y) = \frac{1 - \beta}{1 - \beta^{n_y}} \mathcal{L}({\bf p}, y)&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Class-Balanced-Loss-Based-on-Effective-Number-of-Samples/figure3.png&quot; width=&quot;600px&quot; alt=&quot;Figure 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Class-balanced loss を一般的な損失関数に適用した場合は以下の通りになる。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Class-balanced softmax cross-entropy
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm CB}_{\rm softmax}({\bf z}, y) = - \frac{1 - \beta}{1 - \beta^{n_y}} \log{\left( \frac{\exp{(z_y)}}{\sum_{j=1}^{C} \exp{(z_j)}} \right)}&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Class-balanced sigmoid cross-entropy
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm CB}_{\rm sigmoid}({\bf z}, y) = - \frac{1 - \beta}{1 - \beta^{n_y}} \sum_{i=1}^{C} \log{\left(\frac{1}{1+\exp{(-z_{i}^{t})}} \right)}&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Class-balanced focal loss
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm CB}_{\rm focal}({\bf z}, y) = \frac{1 - \beta}{1 - \beta^{n_y}} \sum_{i=1}^{C} (1 - p_{i}^{t})^{\gamma} \log{(p_{i}^{t})}&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;CIFAR10/100 に対して imbalanced factor を元にデータの分布を擬似的に不均衡にした &lt;code class=&quot;highlighter-rouge&quot;&gt;long-tailed CIFAR10/100&lt;/code&gt; 、&lt;code class=&quot;highlighter-rouge&quot;&gt;iNatiralist&lt;/code&gt; 、&lt;code class=&quot;highlighter-rouge&quot;&gt;ImageNet&lt;/code&gt; を用いて、ベースラインのモデルと class-balanced loss を導入したモデルの比較を行っている。&lt;/p&gt;

&lt;p&gt;Sigmoid ベースの loss を用いる場合は、最終全結合層のバイアスに対してクラスの事前確率を &lt;script type=&quot;math/tex&quot;&gt;\pi = 1/C&lt;/script&gt; として、&lt;script type=&quot;math/tex&quot;&gt;b = - \log{((1 - \pi)/{\pi})}&lt;/script&gt; として初期化し、バイアス項にのみ weight decay を適用している。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;p&gt;画像認識タスクでは主に softmax cross-entropy が用いられるが、バイアス項を適切に初期化した sigmoid cross-entropy や focal loss が softmax cross-entropy を凌駕する結果を示した。&lt;/p&gt;

&lt;p&gt;Class-balanced loss のハイパーパラーメタである &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt; は CIFAR-10 の場合 &lt;script type=&quot;math/tex&quot;&gt;0.9999&lt;/script&gt; であったが、CIFAR-100 の場合は imbalanced factor ごとに異なる &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt; の設定が必要であった。&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;h3 id=&quot;re-sampling-ベースの手法&quot;&gt;Re-sampling ベースの手法&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://link.springer.com/chapter/10.1007/978-3-319-46478-7_29&quot;&gt;Shen, Li, Zhouchen Lin, and Qingming Huang. “Relay backpropagation for effective learning of deep convolutional neural networks.” European conference on computer vision. Springer, Cham, 2016.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.00941&quot;&gt;Geifman, Yonatan, and Ran El-Yaniv. “Deep active learning over the long tail.” arXiv preprint arXiv:1711.00941 (2017).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0893608018302107&quot;&gt;Buda, Mateusz, Atsuto Maki, and Maciej A. Mazurowski. “A systematic study of the class imbalance problem in convolutional neural networks.” Neural Networks 106 (2018): 249-259.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.07911&quot;&gt;Zou, Yang, et al. “Domain adaptation for semantic segmentation via class-balanced self-training.” arXiv preprint arXiv:1810.07911 (2018).&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.6858&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Drummond, Chris, and Robert C. Holte. “C4. 5, class imbalance, and cost sensitivity: why under-sampling beats over-sampling.” Workshop on learning from imbalanced datasets II. Vol. 11. Washington, DC: Citeseer, 2003.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.jair.org/papers/paper953.html&quot;&gt;Chawla, Nitesh V., et al. “SMOTE: synthetic minority over-sampling technique.” Journal of artificial intelligence research 16 (2002): 321-357.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cost-sensitive-learning-ベースの手法&quot;&gt;Cost-Sensitive Learning ベースの手法&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.8819&quot;&gt;Ting, Kai Ming. “A comparative study of cost-sensitive boosting algorithms.” In Proceedings of the 17th International Conference on Machine Learning. 2000.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.computer.org/csdl/trans/tk/2006/01/k0063-abs.html&quot;&gt;Zhou, Zhi-Hua, and Xu-Ying Liu. “Training cost-sensitive neural networks with methods addressing the class imbalance problem.” IEEE Transactions on Knowledge &amp;amp; Data Engineering 1 (2006): 63-77.&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/8012579/&quot;&gt;Khan, Salman H., et al. “Cost-sensitive learning of deep feature representations from imbalanced data.” IEEE transactions on neural networks and learning systems 29.8 (2018): 3573-3587.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_ECCV_2018/html/Nikolaos_Sarafianos_Deep_Imbalanced_Attribute_ECCV_2018_paper.html&quot;&gt;Sarafianos, Nikolaos, Xiang Xu, and Ioannis A. Kakadiaris. “Deep imbalanced attribute classification using visual attention aggregation.” Proceedings of the European Conference on Computer Vision (ECCV). 2018.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;importance-sampling&quot;&gt;Importance sampling&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://pubsonline.informs.org/doi/abs/10.1287/opre.1.5.263&quot;&gt;Kahn, Herman, and Andy W. Marshall. “Methods of reducing sample size in Monte Carlo computations.” Journal of the Operations Research Society of America 1.5 (1953): 263-278.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;決定境界を一定に調整&quot;&gt;決定境界を一定に調整&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://cseweb.ucsd.edu/~elkan/rescale.pdf&quot;&gt;Elkan, Charles. “The foundations of cost-sensitive learning.” International joint conference on artificial intelligence. Vol. 17. No. 1. Lawrence Erlbaum Associates Ltd, 2001.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;クラス数の逆数で重み付け&quot;&gt;クラス数の逆数で重み付け&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7278-learning-to-model-the-tail&quot;&gt;Wang, Yu-Xiong, Deva Ramanan, and Martial Hebert. “Learning to model the tail.” Advances in Neural Information Processing Systems. 2017.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Huang_Learning_Deep_Representation_CVPR_2016_paper.html&quot;&gt;Huang, Chen, et al. “Learning deep representation for imbalanced classification.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;クラス数の逆数の平方根で重み付け&quot;&gt;クラス数の逆数の平方根で重み付け&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/5021-distributed-representations-of-words-andphrases&quot;&gt;Mikolov, Tomas, et al. “Distributed representations of words and phrases and their compositionality.” Advances in neural information processing systems. 2013.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_ECCV_2018/html/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.html&quot;&gt;Mahajan, Dhruv, et al. “Exploring the limits of weakly supervised pretraining.” Proceedings of the European Conference on Computer Vision (ECCV). 2018.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;難しいサンプルにフォーカスして学習&quot;&gt;難しいサンプルにフォーカスして学習&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S002200009791504X&quot;&gt;Freund, Yoav, and Robert E. Schapire. “A decision-theoretic generalization of on-line learning and an application to boosting.” Journal of computer and system sciences 55.1 (1997): 119-139.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.208.446&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Malisiewicz, Tomasz, Abhinav Gupta, and Alexei A. Efros. “Ensemble of exemplar-SVMs for object detection and beyond.” Iccv. Vol. 1. No. 2. 2011.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_iccv_2017/html/Dong_Class_Rectification_Hard_ICCV_2017_paper.html&quot;&gt;Dong, Qi, Shaogang Gong, and Xiatian Zhu. “Class rectification hard mining for imbalanced deep learning.” Proceedings of the IEEE International Conference on Computer Vision. 2017.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_iccv_2017/html/Lin_Focal_Loss_for_ICCV_2017_paper.html&quot;&gt;Lin, Tsung-Yi, et al. “Focal loss for dense object detection.” Proceedings of the IEEE international conference on computer vision. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ノイジーなデータやラベルミスなデータにフォーカスして学習&quot;&gt;ノイジーなデータやラベルミスなデータにフォーカスして学習&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3305576&quot;&gt;Koh, Pang Wei, and Percy Liang. “Understanding black-box predictions via influence functions.” Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1803.09050&quot;&gt;Ren, Mengye, et al. “Learning to reweight examples for robust deep learning.” arXiv preprint arXiv:1803.09050 (2018).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1901.05555&quot;&gt;Cui, Yin, et al. “Class-Balanced Loss Based on Effective Number of Samples.” arXiv preprint arXiv:1901.05555 (2019).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Attention Convolutional Neural Network for Advertiser level Click through Rate Forecasting</title><link href="https://shunk031.github.io/paper-survey/summary/others/Attention-Convolutional-Neural-Network-for-Advertiser-level-Click-through-Rate-Forecasting" rel="alternate" type="text/html" title="Attention Convolutional Neural Network for Advertiser level Click through Rate Forecasting" /><published>2019-05-09T00:00:00+00:00</published><updated>2019-05-09T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/others/Attention-Convolutional-Neural-Network-for-Advertiser-level-Click-through-Rate-Forecasting</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/others/Attention-Convolutional-Neural-Network-for-Advertiser-level-Click-through-Rate-Forecasting">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;広告主単位&lt;/code&gt; という新たな視点で CTR 予測を行う Context-aware Attention Convolutional Neural Network を提案した。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;CTR 予測問題はオンライン広告における重要な問題の 1 つである。先行研究では &lt;code class=&quot;highlighter-rouge&quot;&gt;ユーザ単位&lt;/code&gt; の CTR 予測モデルの提案は複数行われているが、 &lt;code class=&quot;highlighter-rouge&quot;&gt;広告主単位&lt;/code&gt; での予測は本研究が著者が知りうる限りで初めてである。
通常集計されたログデータをモデルに入力するが、本研究ではログデータを時系列データとみなししてモデルに入力し学習を行う。&lt;/p&gt;

&lt;p&gt;本研究では、以下の特徴を持つ context-aware attention convolutional neural network (CACNN) を提案し、実世界のデータセットに対して CTR 予測を行った結果を報告している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/others/Attention-Convolutional-Neural-Network-for-Advertiser-level-Click-through-Rate-Forecasting/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;context-aware-attention-convolutional-neural-network-cacnn&quot;&gt;Context-aware Attention Convolutional Neural Network (CACNN)&lt;/h3&gt;
&lt;p&gt;時系列の CTR データに対する Attention CNN とコンテキストデータ対する MLP からなるネットワーク構造を持つ。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;時系列の CTR データに対する Attention CNN
    &lt;ul&gt;
      &lt;li&gt;畳み込みで得られた特徴マップに対して attention weight を掛ける
        &lt;ul&gt;
          &lt;li&gt;局所的な非線形性や季節性の傾向を適切に捉えることが可能&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;コンテキストデータに対する MLP
    &lt;ul&gt;
      &lt;li&gt;本研究では配信対象の国とデバイスタイプを使用する
        &lt;ul&gt;
          &lt;li&gt;実際の CTR と国・デバイスタイプは相関関係にあるため、これらの情報を適切に捉えることが重要&lt;/li&gt;
          &lt;li&gt;通常こうした特徴量は同一空間上には存在しないが、複数の全結合層を経て concat することにより、同一の潜在空間で扱うことが可能&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;インターネット企業の主要な広告プラットフォームから 30 日分の広告キャンペーンデータ 20 万件程度を取得し、これらを元に評価を行っている。
ベースラインのモデルとして古典的な手法 (exponential moving average 系)と深層学習ベースの手法 (CNN, CNN with Attention 等)と提案手法である CACNN の比較を行っている。&lt;/p&gt;

&lt;h3 id=&quot;学習方法と評価方法について&quot;&gt;学習方法と評価方法について&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;train として 29 日分のデータを使用した。
    &lt;ul&gt;
      &lt;li&gt;28 日目までのデータを使って 29 日目を予測するよう学習を行う。&lt;/li&gt;
      &lt;li&gt;valid として train からランダムに 10%程度サンプリングして使用した。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;test として 30 日目のデータを使用した。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;
&lt;h3 id=&quot;畳み込み操作の効果の確認&quot;&gt;畳み込み操作の効果の確認&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/others/Attention-Convolutional-Neural-Network-for-Advertiser-level-Click-through-Rate-Forecasting/figure12.png&quot; alt=&quot;Figure 12&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ランダムに時系列の CTR データをサンプリングし、それらに対する畳み込み後の特徴マップの状態を可視化したもの。
    &lt;ul&gt;
      &lt;li&gt;異なるカーネルサイズで異なる時系列の特徴を捉えていることが分かる。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;attention-の効果確認&quot;&gt;Attention の効果確認&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Figure 13 (a)&lt;/th&gt;
      &lt;th&gt;Figure 13 (b)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;/paper-survey/assets/img/others/Attention-Convolutional-Neural-Network-for-Advertiser-level-Click-through-Rate-Forecasting/figure13a.png&quot; alt=&quot;Figure 13 (a)&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;/paper-survey/assets/img/others/Attention-Convolutional-Neural-Network-for-Advertiser-level-Click-through-Rate-Forecasting/figure13b.png&quot; alt=&quot;Figure 13 (b)&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Figure 13 (a) : ある特徴マップ 50 個を対象に、それらに対する attention の重みを可視化した図&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Figure 13 (b) : (a)の特徴マップ先頭 3 つを対象に、時系列データを入力したときの特徴マップ値の変化を可視化したもの。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Figure 13 (a) において、特徴マップ 1 と特徴マップ 3 は attention の重みが似ている。
    &lt;ul&gt;
      &lt;li&gt;Figure 13 (b) で特徴マップ 1 (赤) と 特徴マップ 3 (青) は時系列データに対して同様の反応をしている。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;特徴マップ 2 は、1 と 3 と同様の傾向の反応パターンを示しているが、元の時系列データ (黄) と大きさという点では離れている。
    &lt;ul&gt;
      &lt;li&gt;大きな誤差に対して学習された attention の重みが小さくなっているため、最終的な予測誤差は小さくなっていると考えられる。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;
&lt;p&gt;特になし。&lt;/p&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3186184&quot;&gt;Gao, Hongchang, et al. “Attention Convolutional Neural Network for Advertiser-level Click-through Rate Forecasting.” Proceedings of the 2018 World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2018.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Beyond News Contents: The Role of Social Context for Fake News Detection</title><link href="https://shunk031.github.io/paper-survey/summary/others/Beyond-News-Contents-The-Role-of-Social-Context-for-Fake-News-Detection" rel="alternate" type="text/html" title="Beyond News Contents: The Role of Social Context for Fake News Detection" /><published>2019-03-20T00:00:00+00:00</published><updated>2019-03-20T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/others/Beyond-News-Contents-The-Role-of-Social-Context-for-Fake-News-Detection</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/others/Beyond-News-Contents-The-Role-of-Social-Context-for-Fake-News-Detection">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;出版社・ニュース記事・ユーザの 3 つの関係をモデリングすることでフェイクニュース検出の精度向上を目指す TriFN を提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;フェイクニュース検出は主にニュース記事にフォーカスしたものと、ユーザのソーシャルな行動にフォーカスしているものが多い。
これらは偽の情報を判断する言語的な観点やフェイク画像に対する視覚的観点に基づいたモデルの構築を行っている。
またユーザに対して行動ログベースやユーザ間のネットワークベースのモデリングを行っている事例も多い。&lt;/p&gt;

&lt;p&gt;本研究では、先行研究では考慮されてこなかった、&lt;code class=&quot;highlighter-rouge&quot;&gt;出版社&lt;/code&gt;・&lt;code class=&quot;highlighter-rouge&quot;&gt;ニュース記事&lt;/code&gt;・&lt;code class=&quot;highlighter-rouge&quot;&gt;ユーザ行動&lt;/code&gt;の 3 つの関係 &lt;code class=&quot;highlighter-rouge&quot;&gt;tri-relationship&lt;/code&gt; を考慮することでフェイクニュース検出の精度向上を目指す TriFN を提案している。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/others/Beyond-News-Contents-The-Role-of-Social-Context-for-Fake-News-Detection/figure1.png&quot; width=&quot;400px&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/others/Beyond-News-Contents-The-Role-of-Social-Context-for-Fake-News-Detection/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tri-relationship-を考慮したフェイクニュース検出モデル-trifn&quot;&gt;Tri-relationship を考慮したフェイクニュース検出モデル TriFN&lt;/h3&gt;
&lt;p&gt;TriFN は主に non-negative matrix factorization (NMF) をベースとした 5 つのコンポーネントから構成される。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;News Contents Embedding
    &lt;ul&gt;
      &lt;li&gt;Bag-of-words 表現なニュース記事から NMF でニュース記事の潜在表現を学習する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;User Embedding
    &lt;ul&gt;
      &lt;li&gt;ユーザのソーシャルな関係から NMF でユーザの潜在表現を学習する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;User-News Interaction Embedding
    &lt;ul&gt;
      &lt;li&gt;ユーザの信頼度によって得られるニュース記事の潜在表現を学習する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Publisher-News Relation Embedding
    &lt;ul&gt;
      &lt;li&gt;出版社の党派的なバイアスを考慮したニュース記事の潜在表現を学習する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Semi-supervised Linear Classifier
    &lt;ul&gt;
      &lt;li&gt;ニュース記事に対してフェイクニュース予測を行うための学習器を学習する&lt;/li&gt;
      &lt;li&gt;半教師あり学習の枠組みを同時に使用し、ラベルが付与されていないデータからも学習する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;FakeNewsNet データセットを用いて、&lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt;か&lt;code class=&quot;highlighter-rouge&quot;&gt;fake&lt;/code&gt;かの 2 値分類問題としてフェイクニュース検出に対する検出精度の比較を行っている。
比較対象として先行研究で提案されている複数の特徴抽出手法 (RST, LIWC, Castillo とこれらを組み合わせた RST + Castillo, LIWC + Castillo) とベースラインのモデル (LogReg, NBayes, DTree, RForest, XGBoost, AdaBoost, Gradient Boosting) で比較している。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;早期のフェイクニュース検出におけるパフォーマンス
    &lt;ul&gt;
      &lt;li&gt;記事公開から 12 時間後 〜 96 時間後の各時間におけるフェイクニュース検出の精度比較を行った結果、提案手法の TriFN が一番良かった。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;モデルのパラメータ分析
    &lt;ul&gt;
      &lt;li&gt;ユーザのソーシャルな関係の寄与をコントロールするパラメータを大きくすると精度が向上した。
        &lt;ul&gt;
          &lt;li&gt;ユーザとニュース間の関係よりユーザのソーシャルな関係のほうが予測に寄与する。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;フェイクニュース検出における data augmentation
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/8594871/&quot;&gt;Shu, Kai, et al. “Deep headline generation for clickbait detection.” 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 2018.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1712.07709&quot;&gt;Shu, Kai, Suhang Wang, and Huan Liu. “Beyond News Contents: The Role of Social Context for Fake News Detection.” Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining. ACM, 2019.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">How Large Vocabulary Does Text Classification Need? A Variational Approach to Vocabulary Selection</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/How-Large-Vocabulary-Does-Text-Classification-Need-A-Variational-Approach-to-Vocabulary-Selection" rel="alternate" type="text/html" title="How Large Vocabulary Does Text Classification Need? A Variational Approach to Vocabulary Selection" /><published>2019-03-02T00:00:00+00:00</published><updated>2019-03-02T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/How-Large-Vocabulary-Does-Text-Classification-Need-A-Variational-Approach-to-Vocabulary-Selection</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/How-Large-Vocabulary-Does-Text-Classification-Need-A-Variational-Approach-to-Vocabulary-Selection">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;精度を保ったまま最小限の語彙を選択する variational vocabulary dropout (VDD) を提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;自然言語処理 (NLP) のタスクに対して deep learning モデルを用いる場合、入力にあらかじめ定義された語彙を元に単語をベクトル化して入力する必要がある。
こうした語彙数は非常に大規模となる場合が多くパラメータ数も増大してしまうため、限られた計算リソース下での実行することは難しい。
したがってタスクを解く精度を保ったまま必要な語彙を選択する必要がある。&lt;/p&gt;

&lt;p&gt;本研究ではこの語彙選択問題に対して、タスクを考慮した語彙選択手法である variational vocabulary dropoput (VDD) を提案している。
また適切な語彙選択が行われているかを確認するため、AUC ベースの評価指標を導入し、提案手法の効果を確認している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;
&lt;h3 id=&quot;語彙選択に対する問題設定&quot;&gt;語彙選択に対する問題設定&lt;/h3&gt;
&lt;p&gt;元の embedding &lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;と語彙選択を行った後の embedding &lt;script type=&quot;math/tex&quot;&gt;\hat{W}&lt;/script&gt; を使用した場合に、予測精度の差が閾値以上である語彙数を最小にする。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathop{\rm argmin}\limits_{\hat{W},\hat{\theta}} \textrm{#Row}(\hat{W})~~s.t. \textrm{Acc}(f_{\hat{\theta}}(x; \hat{W}), y) - \textrm{Acc}(f_{\theta}(x;W),y)\le \epsilon&lt;/script&gt;

&lt;h3 id=&quot;語彙選択に対する評価指標&quot;&gt;語彙選択に対する評価指標&lt;/h3&gt;
&lt;p&gt;AUC ベースの評価指標 &lt;code class=&quot;highlighter-rouge&quot;&gt;Vocab@-X%&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;X ％のパフォーマンス低下が許される場合に必要な最小の語彙数を計算する
    &lt;ul&gt;
      &lt;li&gt;本研究では &lt;code class=&quot;highlighter-rouge&quot;&gt;Vocab@-3%&lt;/code&gt; および &lt;code class=&quot;highlighter-rouge&quot;&gt;Vocab@-5%&lt;/code&gt; を用いている&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;variational-vocabulary-dropout-vdd&quot;&gt;Variational Vocabulary Dropout (VDD)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Bernouli Dropout
    &lt;ul&gt;
      &lt;li&gt;Onehot ベクトルに対してベルヌーイノイズ&lt;script type=&quot;math/tex&quot;&gt;\textbf{b}&lt;/script&gt;を適用する
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;E(x|\textbf{b}) = (\textbf{b} \odot \textrm{OneHot}(x)) \cdot W&lt;/script&gt;
            &lt;ul&gt;
              &lt;li&gt;しかしながらベルヌーイ分布を reparameterize するのは難しい&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Gaussian Relaxation
    &lt;ul&gt;
      &lt;li&gt;ベルヌーイノイズの代わりにガウシアンノイズ &lt;script type=&quot;math/tex&quot;&gt;z_i \sim \mathcal{N}(1, \alpha_{i} = \frac{p_i}{1 - p_i})&lt;/script&gt; を適用する
        &lt;ul&gt;
          &lt;li&gt;
            &lt;script type=&quot;math/tex; mode=display&quot;&gt;E(x|\textbf{z}) = (\textbf{z} \odot \textrm{OneHot}(x) \cdot W)&lt;/script&gt;
            &lt;ul&gt;
              &lt;li&gt;Reparameterization trick に従うと、&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt; は多変量ガウス分布 &lt;script type=&quot;math/tex&quot;&gt;B&lt;/script&gt; を用いて以下のようになる
                &lt;ul&gt;
                  &lt;li&gt;
                    &lt;script type=&quot;math/tex; mode=display&quot;&gt;E(x|\textbf{z}) = \textrm{OneHot}(x) \cdot B&lt;/script&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/How-Large-Vocabulary-Does-Text-Classification-Need-A-Variational-Approach-to-Vocabulary-Selection/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Dropout 率 &lt;script type=&quot;math/tex&quot;&gt;\alpha_i&lt;/script&gt; は 語彙の&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;番目の単語が必要かどうかを示す指標となる。
ここで&lt;script type=&quot;math/tex&quot;&gt;\alpha_i&lt;/script&gt;より数値が大きい場合は&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;番目の語彙をドロップしてもパフォーマンス低下の要因にならないことを意味する。&lt;/p&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;文書分類 (document classification: DC)、自然言語理解 (natural language understanding: NLU)、自然言語推論 (natural language inference: NLI) のデータセットを用いてそれぞれのタスクにおける VVD の効果を確認している。
提案手法の VVD に対して、ベースラインとして頻度に基づいた語彙形成、TF-IDF に基づいた語彙形成、そして group lasso に基づいた語彙形成を比較している。
各タスクではそれぞれ DC では CNN ベースのモデル、NLU では attetion を導入した bi-directional LSTM モデル、NLI では ESIM モデルを用いている。&lt;/p&gt;

&lt;p&gt;すべてのタスクに対して提案手法の語彙選択手法である VVD が outperform する結果となっている。
また語彙選択を考慮した評価指標として Vocab@-X% を用いた場合では、特に提案手法のスコアが良くなっていることが示されており、効果的な語彙選択が行われていることがわかる。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;h3 id=&quot;学習時の速度について&quot;&gt;学習時の速度について&lt;/h3&gt;
&lt;p&gt;VVD は確率的な振る舞いを扱うため、テキスト分類に対して学習を行う場合通常の cross entropy よりも時間がかかった。
フルサイズの語彙に対して VVD を適用すると計算時間がかかるため、前段階で精度低下が怒らない程度に語彙を制限したほうがよい。&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Deep learning モデルに対するベイジアンベースのモデル圧縮について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/6921-bayesian-compression-for-deep-learning&quot;&gt;Louizos, Christos, Karen Ullrich, and Max Welling. “Bayesian compression for deep learning.” Advances in Neural Information Processing Systems. 2017.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1902.10339&quot;&gt;Wenhu Chen, Yu Su, Yilin Shen, Zhiyu Chen, Xifeng Yan, William Wang. How Large Vocabulary Does Text Classification Need? A Variational Approach to Vocabulary Selection. arXiv:1902.10339, 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Attentional Encoder Network for Targeted Sentiment Classification</title><link href="https://shunk031.github.io/paper-survey/summary/nlp/Attentional-Encoder-Network-for-Targeted-Sentiment-Classification" rel="alternate" type="text/html" title="Attentional Encoder Network for Targeted Sentiment Classification" /><published>2019-03-01T00:00:00+00:00</published><updated>2019-03-01T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/nlp/Attentional-Encoder-Network-for-Targeted-Sentiment-Classification</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/nlp/Attentional-Encoder-Network-for-Targeted-Sentiment-Classification">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;ターゲットに対する感情分析で使われてきた LSTM に変わる self-attention ベースの attentional encoder network (AEN) を提案した。
また付与されている感情ラベルに対する非信頼性に対して label smoothing を行う損失関数を導入した。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;自然言語処理 (NLP) のタスクに対して RNN ベースの LSTM モデルが広く用いられてきたが、
コンテキスト内のターゲットに対する感情を分析する fine-grained なターゲットに対する感情分類 (targeted sentiment classification) に対しては依然として改善の余地が残されている。
先行研究の問題点としてはテキストのモデリングにおいて RNN ベースのモデルに比重がおかれており、また学習速度も遅いことが挙げられる。
感情分類タスクにおいて attention は重要な役割を果たすが、モデルの後段部分でのみしか使用されてこなかった。
また感情分類タスクにおいて付与されている感情ラベルは信頼性が低い場合がある。特に &lt;em&gt;neutral&lt;/em&gt; な感情ラベルはとてもファジーでモデルの学習を難しくしている。&lt;/p&gt;

&lt;p&gt;本研究では fine-grained なターゲットに対する感情分析にタスクに対してターゲットとコンテキストの交互作用を self-attention で捉え、ファジーな感情ラベルに対して効果的な label smoothing を行う損失関数を導入した。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;Attentional Encoder Network &lt;code class=&quot;highlighter-rouge&quot;&gt;(AEN)&lt;/code&gt; を提案&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Attentional-Encoder-Network-for-Targeted-Sentiment-Classification/figure1.png&quot; alt=&quot;Figure 1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;attentional-encoder-layer&quot;&gt;Attentional Encoder Layer&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;LSTM に代わる並列計算可能なレイヤー
    &lt;ul&gt;
      &lt;li&gt;コンテキストとターゲットの embedding に対して隠れ状態の表現を計算&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Multi-Head Attention&lt;/code&gt; と &lt;code class=&quot;highlighter-rouge&quot;&gt;Point-wise Convolutional Transformation&lt;/code&gt; から構成される&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;multi-head-attention-mha&quot;&gt;Multi-Head Attention (MHA)&lt;/h4&gt;
&lt;p&gt;入力されるコンテキストとターゲットに対して異なる MHA を適用する。
MHA は RNN と比較して短いネットワークで離れた単語のコンテキストを捉えることが可能。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Intra-MHA
    &lt;ul&gt;
      &lt;li&gt;コンテキスト embedding &lt;script type=&quot;math/tex&quot;&gt;\textbf{e}^c&lt;/script&gt; を MHA に入力&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf{e}^{\textrm{intra}} = MHA(\textbf{e}^c, \textbf{e}^c)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Inter-MHA
    &lt;ul&gt;
      &lt;li&gt;コンテキスト embedding &lt;script type=&quot;math/tex&quot;&gt;\textbf{e}^c&lt;/script&gt; と ターゲット embedding &lt;script type=&quot;math/tex&quot;&gt;\textbf{e}^t&lt;/script&gt; を MHA に入力&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textbf{e}^{\textrm{inter}} = MHA(\textbf{e}^c, \textbf{e}^t)&lt;/script&gt;

&lt;h4 id=&quot;point-wise-convolution-transformation-pct&quot;&gt;Point-wise Convolution Transformation (PCT)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;2 つの 1D convolution と活性化関数から構成される&lt;/li&gt;
  &lt;li&gt;MHA で得られた表現に対して位置ごとにコンテキストを学習することが可能&lt;/li&gt;
  &lt;li&gt;Intra-MHA と inter-MHA それぞれに対して PCT を適用し、コンテキスト表現を得る&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;label-smoothing-regularization-lsr&quot;&gt;Label Smoothing Regularization (LSR)&lt;/h3&gt;

&lt;p&gt;感情分類タスクに対して &lt;em&gt;neutral&lt;/em&gt; というラベルはとてもファジーであるため、LSR を導入し、過学習を抑制している。
LSR は感情ラベルの分布とモデル予測の分布との KL 距離に等しいため、LSR 項は以下のように表せる。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{lsr} = - D_{\textrm{KL}} (u(k)||p_{\theta})&lt;/script&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;SemEval 2014 Task4 (レストランのレビューデータセット、ラップトップのレビューデータセット)、ACL 14 Twitter データセットの 3 つで比較を行っている。
これらのデータセットには 3 つの感情ラベル (positive/neutral/negative) が付与されている。&lt;/p&gt;

&lt;p&gt;ベースラインのモデルとして SVM、Rec-NN、TD-LSTM、ATAE-LSTM、IAN、MemNet、RAM を用いて提案手法の AEN との比較を行っている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;
&lt;h3 id=&quot;label-smoothing-regularization-の効果&quot;&gt;Label smoothing regularization の効果&lt;/h3&gt;
&lt;p&gt;Label smoothing regularization を導入することで、導入していないモデルよりも良い精度であった。
信頼性の低いラベルに対して効果的に過学習を抑制できたと考えられる。&lt;/p&gt;

&lt;h3 id=&quot;recurrence-vsattention&quot;&gt;Recurrence vs.Attention&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/nlp/Attentional-Encoder-Network-for-Targeted-Sentiment-Classification/table3.png&quot; width=&quot;400px&quot; alt=&quot;Table 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;AEN に対して Attention encoder layer を LSTM に代えたネットワークと比較すると同等程度の精度を記録している。
よって LSTM に比べて半数程度の少ないパラメータで同程度の予測精度を達成できるメリットがある。&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Multi-Head Atteition について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://papers.nips.cc/paper/7181-attention-is-all-you-need&quot;&gt;Vaswani, Ashish, et al. “Attention is all you need.” Advances in Neural Information Processing Systems. 2017.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Label Smoothing Regularization について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.html&quot;&gt;Szegedy, Christian, et al. “Rethinking the inception architecture for computer vision.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1902.09314&quot;&gt;Song, Youwei, et al. “Attentional Encoder Network for Targeted Sentiment Classification.” arXiv preprint arXiv:1902.09314 (2019).&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">Tell Me Where to Look: Guided Attention Inference Network</title><link href="https://shunk031.github.io/paper-survey/summary/cv/Tell-Me-Where-to-Look-Guided-Attention-Inference-Network" rel="alternate" type="text/html" title="Tell Me Where to Look: Guided Attention Inference Network" /><published>2019-02-24T00:00:00+00:00</published><updated>2019-02-24T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/cv/Tell-Me-Where-to-Look-Guided-Attention-Inference-Network</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/cv/Tell-Me-Where-to-Look-Guided-Attention-Inference-Network">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;Attention map を用いた弱教師ありセマンティックセグメンテーションを高精度に行う guided attention inference networks (GAIN) を提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;クラスラベルをもとに学習し予測することで得られる attention map は局所的な特徴やセグメンテーションの情報を保持している場合が多い。
こうした attention map を利用しセマンティックセグメンテーションといったタスクを解く弱教師あり学習 (weakly supervised learning) の枠組みは先行研究で複数手法が提案されてきた。
しかしながらクラスラベルから classification loss で学習した attention map は分類に必要最低限の領域にのみフォーカスしており、対象となる物体全体をカバーすることは難しい。&lt;/p&gt;

&lt;p&gt;また学習データセットのバイアスにより、未知のデータに対して正しくセグメンテーションを行うのは難しい。
具体的には&lt;code class=&quot;highlighter-rouge&quot;&gt;ボート&lt;/code&gt;と&lt;code class=&quot;highlighter-rouge&quot;&gt;海&lt;/code&gt;は同時に撮影される場合が多く、高い相関がある。
したがって予測時に海面が移っていない&lt;code class=&quot;highlighter-rouge&quot;&gt;ボート&lt;/code&gt;のサンプルを正しくセグメンテーションするのは難しい場合が多い。&lt;/p&gt;

&lt;p&gt;本研究では end-to-end で attention map を学習し、classification loss に加えて attention の妥当性を考慮する loss を同時に学習する guided attention inference networks (GAIN) を提案している。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;h3 id=&quot;gain&quot;&gt;GAIN&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Tell-Me-Where-to-Look-Guided-Attention-Inference-Network/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;共通する 2 つのストリーム (&lt;script type=&quot;math/tex&quot;&gt;S_{cl}&lt;/script&gt; と &lt;script type=&quot;math/tex&quot;&gt;S_{am}&lt;/script&gt;)
    &lt;ul&gt;
      &lt;li&gt;2 つのストリームにおける conv 層と一部の fc 層のパラメータは共通&lt;/li&gt;
      &lt;li&gt;Classification stream &lt;script type=&quot;math/tex&quot;&gt;S_{cl}&lt;/script&gt;
        &lt;ul&gt;
          &lt;li&gt;クラスに分類するために役立つ領域を見つけるよう学習&lt;/li&gt;
          &lt;li&gt;マルチラベル・マルチクラスの &lt;code class=&quot;highlighter-rouge&quot;&gt;classification loss&lt;/code&gt; を最小化する&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Attention mining stream &lt;script type=&quot;math/tex&quot;&gt;S_{am}&lt;/script&gt;
        &lt;ul&gt;
          &lt;li&gt;クラスの決定に寄与する可能性があるすべての領域が attention に含まれるよう学習&lt;/li&gt;
          &lt;li&gt;対象クラスに対する attention 領域が大きくならないようにする &lt;code class=&quot;highlighter-rouge&quot;&gt;attention mining loss&lt;/code&gt; を最小化する&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gain_textrmext&quot;&gt;GAIN&lt;script type=&quot;math/tex&quot;&gt;_{\textrm{ext}}&lt;/script&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Tell-Me-Where-to-Look-Guided-Attention-Inference-Network/figure3.png&quot; alt=&quot;Figure 3&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;追加で小規模のセグメンテーションマスクを学習に利用
    &lt;ul&gt;
      &lt;li&gt;External stream &lt;script type=&quot;math/tex&quot;&gt;S_{e}&lt;/script&gt; を追加
        &lt;ul&gt;
          &lt;li&gt;教師となるセグメンテーションマスクから attention map を学習&lt;/li&gt;
          &lt;li&gt;Attention map とセグメンテーションマスクの二乗誤差である &lt;code class=&quot;highlighter-rouge&quot;&gt;attention loss&lt;/code&gt; を最小化する&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;PASCAL VOC を用いた弱教師ありセグメンテーションタスクで先行研究の SoTA モデルとの mean intersection-over-union (mIoU) のスコアを比較している。
SoTA モデルである SEC に対して attention map を用いた提案手法を適用することにより精度向上が確認されている。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Tell-Me-Where-to-Look-Guided-Attention-Inference-Network/figure4.png&quot; alt=&quot;Figure 4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SoTA モデルである SEC に対して GAIN を導入することにより、複数物体を正確に広い範囲で捉えることが可能となっている。
また追加でセグメンテーションマスクを用いることで、より精度のよいセグメンテーションが行われている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/Tell-Me-Where-to-Look-Guided-Attention-Inference-Network/figure6.png&quot; alt=&quot;Figure 6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;学習データセットにバイアスがある場合にベースラインの Grad-CAM と提案手法の GAIN がどのような予測をするか可視化を行った結果。
Grad-CAM は&lt;code class=&quot;highlighter-rouge&quot;&gt;海&lt;/code&gt;とともに現れやすい&lt;code class=&quot;highlighter-rouge&quot;&gt;ボート&lt;/code&gt;に過学習している傾向があるが、GAIN は&lt;code class=&quot;highlighter-rouge&quot;&gt;ボート&lt;/code&gt;を適切に捉えていることがわかる。
提案手法の GAIN がバイアスのあるデータセットに対してもロバストであることを示している。&lt;/p&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;SEC について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.06098&quot;&gt;Kolesnikov, Alexander, and Christoph H. Lampert. “Seed, expand and constrain: Three principles for weakly-supervised image segmentation.” European Conference on Computer Vision. Springer, Cham, 2016.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.10171&quot;&gt;Li, Kunpeng, et al. “Tell me where to look: Guided attention inference network.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry><entry><title type="html">SC-FEGAN: Face Editing Generative Adversarial Networks with User’s Sketch and Color</title><link href="https://shunk031.github.io/paper-survey/summary/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color" rel="alternate" type="text/html" title="SC-FEGAN: Face Editing Generative Adversarial Networks with User's Sketch and Color" /><published>2019-02-21T00:00:00+00:00</published><updated>2019-02-21T00:00:00+00:00</updated><id>https://shunk031.github.io/paper-survey/summary/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color</id><content type="html" xml:base="https://shunk031.github.io/paper-survey/summary/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color">&lt;h2 id=&quot;1-どんなもの&quot;&gt;1. どんなもの？&lt;/h2&gt;

&lt;p&gt;ユーザーのインタラクティブなスケッチや色指定が可能なニューラルネットワークベースの顔画像編集システム SC-FEGAN を提案。&lt;/p&gt;

&lt;h2 id=&quot;2-先行研究と比べてどこがすごいの&quot;&gt;2. 先行研究と比べてどこがすごいの？&lt;/h2&gt;

&lt;p&gt;従来の Generative Adversarial Network (GAN) を用いた顔画像編集システムは低画質でエッジを適切に捉えるのが難しかった。
また顔編集を行う際のユーザの入力に対して質の高い応答を返すのは困難であった。&lt;/p&gt;

&lt;p&gt;Deepfillv2 や Guided inpainting はこうしたユーザーが入力するマスキングや他の画像を入力として編集を可能としたが、編集時の色の指定ができなかったり、詳細な細かい復元が可能ではなかった。&lt;/p&gt;

&lt;p&gt;本研究では UNet ベースのアーキテクチャに対して gated convolutional layer を導入したネットワークアーキテクチャをベースにユーザーのスケッチや色指定を可能とした、
自由で高品質な顔編集システムである SC-FEGAN を提案した。&lt;/p&gt;

&lt;h2 id=&quot;3-技術や手法のキモはどこにある&quot;&gt;3. 技術や手法の”キモ”はどこにある？&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color/figure2.png&quot; alt=&quot;Figure 2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;学習データに対する処理&quot;&gt;学習データに対する処理&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;高品質な瞳の編集
    &lt;ul&gt;
      &lt;li&gt;学習時にランダムに目周辺にマスキングを適用することで細かい瞳の復元を可能とする&lt;/li&gt;
      &lt;li&gt;同時に generative face completion (GFC) を適用する&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ユーザーが入力するスケッチや色指定への対応
    &lt;ul&gt;
      &lt;li&gt;FaceShop と同様の手法を導入
        &lt;ul&gt;
          &lt;li&gt;スケッチデータをビットマップからベクターへと変換する&lt;a href=&quot;http://autotrace.sourceforge.net/&quot;&gt;AutoTrace&lt;/a&gt;は用いていない&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;HED によるエッジ検出器を使用して、ユーザーの入力からスケッチデータを生成&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;提案顔編集システムのアーキテクチャ&quot;&gt;提案顔編集システムのアーキテクチャ&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color/figure3.png&quot; alt=&quot;Figure 3&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Generator
    &lt;ul&gt;
      &lt;li&gt;U-net ベースの generator を採用
        &lt;ul&gt;
          &lt;li&gt;すべての畳み込み層に gated convolution を導入している&lt;/li&gt;
          &lt;li&gt;畳み込みの後に local signal normalization (LRN)を用いている&lt;/li&gt;
          &lt;li&gt;入力は&lt;script type=&quot;math/tex&quot;&gt;512 \times 512 \times 9&lt;/script&gt;である
            &lt;ul&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RGB (3 チャンネル)&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;マスク (1 チャンネル)&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;スケッチ(1 チャンネル)&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;色指定マップ(3 チャンネル)&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;ノイズ(1 チャンネル)&lt;/code&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Discriminator
    &lt;ul&gt;
      &lt;li&gt;SN-patchGAN ベースの discriminator を採用
        &lt;ul&gt;
          &lt;li&gt;複数の loss 関数を最小化する
            &lt;ul&gt;
              &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;per-pixcel loss&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;perceptual loss&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;style loss&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;total variance loss&lt;/code&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-どうやって有効だと検証した&quot;&gt;4. どうやって有効だと検証した？&lt;/h2&gt;

&lt;p&gt;CelebA-HO データセットにおいてランダムに学習用とテスト用で分割したものに対して提案システムである SC-FEGAN による顔編集の質を検討している。&lt;/p&gt;

&lt;h2 id=&quot;5-議論はあるか&quot;&gt;5. 議論はあるか？&lt;/h2&gt;

&lt;h3 id=&quot;generator-の違いによる瞳の編集精度&quot;&gt;Generator の違いによる瞳の編集精度&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color/figure4.png&quot; alt=&quot;Figure 4&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Generator を U-net と Coarse-Refined net で変えたときに、瞳領域をマスクして復元したときの結果。U-net 構造のほうが細かい瞳の復元に成功している&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;perceptual-loss-の有無による編集精度&quot;&gt;Perceptual loss の有無による編集精度&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color/figure5.png&quot; alt=&quot;Figure 5&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Perceptual loss である VGG loss を導入することにより、髪部分が正確に編集できている&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;先行研究との復元精度の比較&quot;&gt;先行研究との復元精度の比較&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color/figure6.png&quot; alt=&quot;Figure 6&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;先行研究の Deepfillv1 に対して提案システムである SC-FEGAN による復元精度が高いことがわかる&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;アクセサリーなどの小さい物体に対する編集の可能性&quot;&gt;アクセサリーなどの小さい物体に対する編集の可能性&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/paper-survey/assets/img/cv/SC-FEGAN-Face-Editing-Generative-Adversarial-Networks-with-Users-Sketch-and-Color/figure8.png&quot; alt=&quot;Figure 8&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;HED をもとにマスキング領域を拡張して学習することにより、イヤリングと共に顔の画像を生成するという特別な結果を得ることができた&lt;/li&gt;
  &lt;li&gt;ネットワークが小さな詳細を学習し、小さな入力に対しても妥当な結果を生み出すことができることを示している&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-次に読むべき論文はあるか&quot;&gt;6. 次に読むべき論文はあるか？&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Deepfillv2 (SN-patchGAN, gated convolutional layer) について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1806.03589&quot;&gt;Yu, Jiahui, et al. “Free-form image inpainting with gated convolution.” arXiv preprint arXiv:1806.03589 (2018).&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Guided inpainting について
    &lt;ul&gt;
      &lt;li&gt;[Zhao, Yinan, et al. “Guided image inpainting: Replacing an image region by pulling content from another image.” arXiv preprint arXiv:1803.08435 (2018).]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Generative Face Completion (GFC) について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_cvpr_2017/html/Li_Generative_Face_Completion_CVPR_2017_paper.html&quot;&gt;Li, Yijun, et al. “Generative face completion.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;FaceShop について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1804.08972&quot;&gt;Portenier, Tiziano, et al. “Faceshop: Deep sketch-based face image editing.” ACM Transactions on Graphics (TOG) 37.4 (2018): 99.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;U-net について
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.cs.cmu.edu/~jeanoh/16-785/papers/ronnenberger-miccai2015-u-net.pdf&quot;&gt;Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. “U-net: Convolutional networks for biomedical image segmentation.” International Conference on Medical image computing and computer-assisted intervention. Springer, Cham, 2015.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;論文情報リンク&quot;&gt;論文情報・リンク&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1902.06838&quot;&gt;Youngjoo Jo, Jongyoul Park. SC-FEGAN: Face Editing Generative Adversarial Network with User’s Sketch and Color. arXiv:1902.06838, 2019&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. どんなもの？</summary></entry></feed>