<!doctype html>
<html ⚡ lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">
  <script async custom-element="amp-install-serviceworker" src="https://cdn.ampproject.org/v0/amp-install-serviceworker-0.1.js"></script>
  <script async custom-element="amp-analytics" src="https://cdn.ampproject.org/v0/amp-analytics-0.1.js"></script>
  <script async custom-element="amp-sidebar" src="https://cdn.ampproject.org/v0/amp-sidebar-0.1.js"></script>
    <script async custom-element="amp-social-share" src="https://cdn.ampproject.org/v0/amp-social-share-0.1.js"></script>
  <title>Deep Learning applied to NLP - Paper Survey</title> <!-- Begin Jekyll SEO tag v2.5.0 -->
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Deep Learning applied to NLP" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1. どんなもの？" />
<meta property="og:description" content="1. どんなもの？" />
<link rel="canonical" href="https://shunk031.github.io/paper-survey/summary/nlp/Deep-Learning-applied-to-NLP" />
<meta property="og:url" content="https://shunk031.github.io/paper-survey/summary/nlp/Deep-Learning-applied-to-NLP" />
<meta property="og:site_name" content="Paper Survey" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-03-13T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@shunk031" />
<script type="application/ld+json">
{"description":"1. どんなもの？","@type":"BlogPosting","url":"https://shunk031.github.io/paper-survey/summary/nlp/Deep-Learning-applied-to-NLP","headline":"Deep Learning applied to NLP","dateModified":"2017-03-13T00:00:00+00:00","datePublished":"2017-03-13T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://shunk031.github.io/paper-survey/summary/nlp/Deep-Learning-applied-to-NLP"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link type="application/atom+xml" rel="alternate" href="https://shunk031.github.io/paper-survey/feed.xml" title="Paper Survey" />
  <style amp-custom>
  
  body,h1,h2,h3,h4,h5,h6,p,blockquote,pre,hr,dl,dd,ol,ul,figure{margin:0;padding:0}body{font:400 16px/1.5 "Open Sans","Helvetica Neue",Helvetica,Arial,sans-serif;color:#606c71;-webkit-text-size-adjust:100%;-webkit-font-feature-settings:"kern" 1;-moz-font-feature-settings:"kern" 1;-o-font-feature-settings:"kern" 1;font-feature-settings:"kern" 1;font-kerning:normal;line-height:1.5}h1,h2,h3,h4,h5,h6,p,blockquote,pre,ul,ol,dl,figure,.highlight{margin-bottom:15px}hr{display:block;border:none;height:1px;margin:40px auto;background:#eee}img{max-width:100%;vertical-align:middle}figure>img{display:block}figcaption{font-size:14px}ul,ol{margin-left:30px}li>ul,li>ol{margin-bottom:0}h1,h2,h3,h4,h5,h6{font-weight:400}a{color:#2a7ae2;text-decoration:none}a:visited{color:#1756a9}a:hover{color:#606c71}blockquote{color:#828282;border-left:4px solid #e8e8e8;padding-left:15px;font-size:18px;letter-spacing:-1px;font-style:italic}blockquote>:last-child{margin-bottom:0}pre,code{font-family:Menlo,Monaco,Courier;font-size:14px;border:1px solid #e8e8e8;border-radius:3px;background-color:#eef}code{padding:1px 5px}pre{padding:8px 12px;overflow-x:auto}pre>code{border:0;padding-right:0;padding-left:0}.default .wrapper{max-width:600px}.wrapper{max-width:-webkit-calc(800px - (30px));max-width:calc(800px - (30px));padding-right:15px;padding-left:15px;margin:0 auto}@media screen and (min-width: 800px){.wrapper{max-width:-webkit-calc(800px - (30px * 2));max-width:calc(800px - (30px * 2));padding:0 30px}}.wrapper:after{content:"";display:table;clear:both}.icon>svg{display:inline-block;width:16px;height:16px;vertical-align:middle}.icon>svg path{fill:#828282}.social-button-item{display:inline-block;vertical-align:top}.site-header{min-height:60px;padding:15px 0;position:relative;background-color:#159957;background-image:linear-gradient(120deg, #155799, #159957)}.site-header a{color:#fff}.header-nav .site-nav{position:absolute;right:40px;top:26px;font-weight:700}.site-title{font-size:26px;font-weight:300;line-height:56px;letter-spacing:-1px;margin-bottom:0;float:left}.site-nav{float:right;position:absolute;top:18px;right:15px;border:1px solid #e8e8e8;border-radius:5px}.site-nav .menu-icon{float:right;width:36px;height:36px;line-height:0;background:none;border:0;outline:0}.site-nav .menu-icon>svg{width:18px;height:15px}.site-nav .menu-icon>svg path{fill:#fff}.site-nav .trigger{clear:both;display:none}@media screen and (min-width: 600px){.site-nav{position:relative;background-color:transparent;border:none}.site-nav .menu-icon{display:none}.site-nav .trigger{display:block}.site-nav .page-link{display:inline}}.page-link{display:block;padding:5px 10px;margin-left:20px}.page-link:not(:last-child){margin-right:0}amp-sidebar{width:200px;padding-right:10px}.amp-close-image{top:10px;left:175px;cursor:pointer}.author{text-align:center;align-items:center;padding:10px;margin:60px 0 10px 0}.author .avatar{width:90px;height:90px;margin:0 auto}.author .avatar img{border-radius:50%;border-color:aliceblue}.author h1{margin:12px 0 0 0;font-size:30px;color:#fff}.author h2{font-size:19px;color:#E0E0E0}.site-footer{padding:30px 0}.site-footer .wrapper{border-top:solid 1px #eff0f1;padding-top:2rem;margin-top:2rem}.site-footer-owner{display:block;font-weight:bold}.site-footer-credits{color:#819198}.page-content{padding:30px 0;display:block}.page-content h1,.page-content h2,.page-content h3,.page-content h4,.page-content h5,.page-content h6{color:#159957;margin-top:1rem;margin-bottom:1rem;font-weight:normal}.page-heading{font-size:20px}.post-list{margin-left:0;list-style:none}.post-list>li{margin-bottom:30px}.post-meta{font-size:14px;color:#828282}.post-link{display:block;font-size:24px}.post-header{margin-bottom:30px;text-align:center}.post-title{font-size:42px;letter-spacing:-1px;line-height:1}@media screen and (min-width: 800px){.post-title{font-size:36px}}.post-content{margin-bottom:30px}.post-content img{max-width:100%;vertical-align:middle;display:block;margin:auto}.post-content h2{font-size:1.5em}@media screen and (min-width: 800px){.post-content h2{font-size:1.5em}}.post-content h3{font-size:1.17em}@media screen and (min-width: 800px){.post-content h3{font-size:1.17em}}.post-content h4{font-size:18px}@media screen and (min-width: 800px){.post-content h4{font-size:20px}}.post-content table{display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all;-webkit-overflow-scrolling:touch;border-collapse:collapse}.post-content table th{font-weight:bold}.post-content table th,.post-content table td{padding:0.5rem 1rem;border:1px solid #e9ebec}.post-content dl{padding:0}.post-content dl dt{padding:0;margin-top:1rem;font-size:1rem;font-weight:bold}.post-content dl dd{padding:0;margin-bottom:1rem}.post-content hr{height:2px;padding:0;margin:1rem 0;background-color:#eff0f1;border:0}.pagination{width:100%;padding:20px 0;display:block;position:relative}.pagination a{background:#E3F2FD;padding:5px 7px}.pagination .prev{float:left}.pagination .next{float:right}.highlight{background:#fff}.highlighter-rouge .highlight{background:#eef}.highlight .c{color:#998;font-style:italic}.highlight .err{color:#a61717;background-color:#e3d2d2}.highlight .k{font-weight:bold}.highlight .o{font-weight:bold}.highlight .cm{color:#998;font-style:italic}.highlight .cp{color:#999;font-weight:bold}.highlight .c1{color:#998;font-style:italic}.highlight .cs{color:#999;font-weight:bold;font-style:italic}.highlight .gd{color:#000;background-color:#fdd}.highlight .gd .x{color:#000;background-color:#faa}.highlight .ge{font-style:italic}.highlight .gr{color:#a00}.highlight .gh{color:#999}.highlight .gi{color:#000;background-color:#dfd}.highlight .gi .x{color:#000;background-color:#afa}.highlight .go{color:#888}.highlight .gp{color:#555}.highlight .gs{font-weight:bold}.highlight .gu{color:#aaa}.highlight .gt{color:#a00}.highlight .kc{font-weight:bold}.highlight .kd{font-weight:bold}.highlight .kp{font-weight:bold}.highlight .kr{font-weight:bold}.highlight .kt{color:#458;font-weight:bold}.highlight .m{color:#099}.highlight .s{color:#d14}.highlight .na{color:teal}.highlight .nb{color:#0086B3}.highlight .nc{color:#458;font-weight:bold}.highlight .no{color:teal}.highlight .ni{color:purple}.highlight .ne{color:#900;font-weight:bold}.highlight .nf{color:#900;font-weight:bold}.highlight .nn{color:#555}.highlight .nt{color:navy}.highlight .nv{color:teal}.highlight .ow{font-weight:bold}.highlight .w{color:#bbb}.highlight .mf{color:#099}.highlight .mh{color:#099}.highlight .mi{color:#099}.highlight .mo{color:#099}.highlight .sb{color:#d14}.highlight .sc{color:#d14}.highlight .sd{color:#d14}.highlight .s2{color:#d14}.highlight .se{color:#d14}.highlight .sh{color:#d14}.highlight .si{color:#d14}.highlight .sx{color:#d14}.highlight .sr{color:#009926}.highlight .s1{color:#d14}.highlight .ss{color:#990073}.highlight .bp{color:#999}.highlight .vc{color:teal}.highlight .vg{color:teal}.highlight .vi{color:teal}.highlight .il{color:#099}

  </style>
    <link rel="apple-touch-icon" sizes="57x57" href="/paper-survey/assets/favicons/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/paper-survey/assets/favicons/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/paper-survey/assets/favicons/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/paper-survey/assets/favicons/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/paper-survey/assets/favicons/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/paper-survey/assets/favicons/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/paper-survey/assets/favicons/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/paper-survey/assets/favicons/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/paper-survey/assets/favicons/apple-icon-180x180.png">
<link rel="icon" type="image/png" href="/paper-survey/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/paper-survey/assets/favicons/android-icon-192x192.png" sizes="192x192">
<link rel="icon" type="image/png" href="/paper-survey/assets/favicons/favicon-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/paper-survey/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="shortcut icon" href="/paper-survey/favicon.ico" type="image/x-icon">
<link rel="icon" href="/paper-survey/favicon.ico" type="image/x-icon">
<link rel="mask-icon" href="/paper-survey/assets/favicons/icon.svg" color="#5bbad5">
<meta name="msapplication-TileImage" content="/paper-survey/assets/favicons/ms-icon-144x144.png">
<link rel="manifest" href="/paper-survey/manifest.json">
<!-- Chrome, Firefox OS and Opera -->
<meta name="theme-color" content="#ffffff">
<!-- Windows Phone -->
<meta name="msapplication-navbutton-color" content="#ffffff">
<meta name=msapplication-TileColor content=#ffffff>
<!-- iOS Safari -->
<meta name="mobile-web-app-capable" content="yes">
<meta name="mobile-web-app-status-bar-style" content="black-translucent">

  <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
  <script async src="https://cdn.ampproject.org/v0.js"></script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>

  <body>
     <amp-sidebar id='sidebar'
    layout="nodisplay"
    side="right">
  <amp-img class='amp-close-image'
      src="/paper-survey/assets/img/close.png"
      width="20"
      height="20"
      alt="close sidebar"
      on="tap:sidebar.close"
      role="button"
      tabindex="0"></amp-img>
      
        
      
        
        <a class="page-link" href="/paper-survey/about/">About</a>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      <a class="page-link" href="/paper-survey/summary/">Summary</a>
      <a class="page-link" href="/paper-survey/category/cv">CV</a>
      <a class="page-link" href="/paper-survey/category/nlp">NLP</a>
      <a class="page-link" href="/paper-survey/category/others">Others</a>
</amp-sidebar>

<header class="site-header">
    <div class="wrapper"><a class="site-title" href="/paper-survey/">Paper Survey</a>

    <nav class="site-nav">
      <button on='tap:sidebar.toggle' class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </button>
      <div class="trigger">
        
          
        
          
          <a class="page-link" href="/paper-survey/about/">About</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
	<a class="page-link" href="/paper-survey/summary/">Summary</a>
	<a class="page-link" href="/paper-survey/category/cv">CV</a>
	<a class="page-link" href="/paper-survey/category/nlp">NLP</a>
	<a class="page-link" href="/paper-survey/category/others">Others</a>
      </div>
    </nav>
  </div>
</header>
 
    <div class="page-content ">
      <div class="wrapper">
	<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Deep Learning applied to NLP</h1>
    <p class="post-meta"><time datetime="2017-03-13T00:00:00+00:00" itemprop="datePublished">Mar 13, 2017</time>
      in 
      <a href="/paper-survey/category/NLP">NLP</a>
      <p>
    </p>
  </header>
  <div class="post-content" itemprop="articleBody">
    <h2 id="1-どんなもの">1. どんなもの？</h2>

<p>近年、コンピュータビジョンの分野で最先端の結果を残すConvolutional Neural Network(CNN)を自然言語処理タスクに適用し、優れたパフォーマンスを発揮した事例を調査する。</p>

<h2 id="2-先行研究と比べてどこがすごいの">2. 先行研究と比べてどこがすごいの？</h2>

<p>人間の脳の構造を模倣したとされるArtificial Neural Network(ANN)は、確率的言語モデリングや構文解析などで利用されてきた。画像認識分野で成功を収めたCNNはANNと似た構造で、畳み込み操作を用いることで局所的な特徴も捉えることができるものである。最近の研究ではこのCNNを自然言語処理タスクに適用することで、ANNが結果を残してきた言語処理タスクにおいて、遥かに凌ぐ素晴らしい結果を出している。</p>

<h2 id="3-技術や手法のキモはどこにある">3. 技術や手法の”キモ”はどこにある？</h2>

<p>ここでは、自然言語処理のさまざまなタスクについてCNNを適用した事例を取り上げていく。</p>

<h3 id="cnnを自然言語処理に適用する動機について">CNNを自然言語処理に適用する動機について</h3>

<ol>
  <li><a href="http://www.aclweb.org/anthology/P15-2#page=208">Bitvai, Zsolt, and Trevor Cohn. “Non-Linear Text Regression with a Deep Convolutional Neural Network.” ACL (2). 2015.</a>では、ANNはこれまで素晴らしい結果を残してきたが、とても規模の大きいデータが手に入るようになってきたため、大規模なデータセットでCNNを学習することでモデルのパラメータ数が多い場合でも効率よく学習を進めることができると考えられている。</li>
</ol>

<h3 id="基本的な自然言語処理について">基本的な自然言語処理について</h3>

<ol>
  <li>
    <p><a href="https://arxiv.org/pdf/1505.05667">Zhu, Chenxi, et al. “A re-ranking model for dependency parser with recursive convolutional neural network.” arXiv preprint arXiv:1505.05667 (2015).</a>では、文や単語から統語論的および構成的意味表現を捉えることができる、Recursive Convolutional Neural Network(RCNN)が提案されている。</p>
  </li>
  <li><a href="http://www.aclweb.org/old_anthology/P/P15/P15-2058.pdf">Wang, Peng, et al. “Semantic Clustering and Convolutional Neural Network for Short Text Categorization.” ACL (2). 2015.</a>では、セマンティッククラスタリングとCNNを用いて短い文章をモデリングする方法が提案されている。</li>
  <li>
    <p><a href="https://arxiv.org/abs/1604.00734">Francis-Landau, Matthew, Greg Durrett, and Dan Klein. “Capturing semantic similarity for entity linking with convolutional neural networks.” arXiv preprint arXiv:1604.00734 (2016).</a>では、記述されている文脈と、対象となる固有表現との間の存在する意味の対応関係を捉えるCNN構造を提案している。</p>
  </li>
  <li><a href="https://arxiv.org/pdf/1611.02361">Zhang, Rui, Honglak Lee, and Dragomir Radev. “Dependency sensitive convolutional neural networks for modeling sentences and documents.” arXiv preprint arXiv:1611.02361 (2016).</a>では、文や文書の両方を一般的な用途で分類できるシステムであるDependency Sensitive Convolutional Neural Networks(DSCNN)を提案している。</li>
</ol>

<h3 id="情報抽出について">情報抽出について</h3>

<ol>
  <li>
    <p><a href="http://www.aclweb.org/anthology/P15-1017">Chen, Yubo, et al. “Event Extraction via Dynamic Multi-Pooling Convolutional Neural Networks.” ACL (1). 2015.</a>では、単語から意味のある規則性を見つけ、そして文レベルで特徴を捉える複数のPooling層を持つCNNをベースとするフレームワークを採用している単語表現モデルを提案している。</p>
  </li>
  <li>
    <p><a href="https://pdfs.semanticscholar.org/30d4/2515df2900edce9b386ea17e4a4e2584fd4c.pdf">Nguyen, Thien Huu, and Ralph Grishman. “Event Detection and Domain Adaptation with Convolutional Neural Networks.” ACL (2). 2015.</a>では、文から特徴を自動的に学習する、イベント検出のためのCNNを提案している。教師データや特徴量への依存を最小化することで、エラーの伝播を緩和することができ、パフォーマンスを改善することができている。</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1605.07333">Vu, Ngoc Thang, et al. “Combining recurrent and convolutional neural networks for relation classification.” arXiv preprint arXiv:1605.07333 (2016).</a>では、「関係を分類するためのCNNの新しいコンテキスト表現」・「Ranking lossを導入したConnectionist bi-directional Recurrent Neural Network」・「シンプルな投票システムを導入したCNNとRNNのコンビネーションモデル」の3つの異なる手法について吟味している。</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1603.05157">Adel, Heike, Benjamin Roth, and Hinrich Schütze. “Comparing convolutional neural networks to traditional models for slot filling.” arXiv preprint arXiv:1603.05157 (2016).</a>では、slot fillingのコンテキストにおける関係分類を扱い、異なる設定で評価を行っている。</p>
  </li>
</ol>

<h3 id="要約について">要約について</h3>

<ol>
  <li><a href="https://arxiv.org/abs/1406.3830">Denil, Misha, et al. “Modelling, visualising and summarising documents with a single convolutional neural network.” arXiv preprint arXiv:1406.3830 (2014).</a>では、意味を捉えるために重要な単語と文の順序を維持しながら、低次元のベクトル空間にembeddingすることによって、文書の意味を表現できるモデルを提案している。</li>
</ol>

<h3 id="機械翻訳について">機械翻訳について</h3>

<ol>
  <li>
    <p><a href="https://arxiv.org/pdf/1503.02357">Tu, Zhaopeng, et al. “Context-dependent translation selection using convolutional neural network.” arXiv preprint arXiv:1503.02357 (2015).</a>では、CNNを用いて2つの言語の対となるフレーズ感の類似性を判断する、統計的機械翻訳の方法を提案している。</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1503.01838">Meng, Fandong, et al. “Encoding source language with convolutional neural network for machine translation.” arXiv preprint arXiv:1503.01838 (2015).</a>では、CNNとゲート構造を利用したアーキテクチャを用いて、対象となる情報から関連する情報を要約することで、より体系的な処理を行えるように工夫している。</p>
  </li>
</ol>

<h3 id="質問応答について">質問応答について</h3>

<ol>
  <li>
    <p><a href="http://www.aclweb.org/website/old_anthology/P/P15/P15-1026.pdf">Dong, Li, et al. “Question Answering over Freebase with Multi-Column Convolutional Neural Networks.” ACL (1). 2015.</a>では、自動的に複数の側面から質問を解析する、multi-column CNN(MCCNN)を提案している。</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1604.01178">Severyn, Aliaksei, and Alessandro Moschitti. “Modeling relational information in question-answer pairs with convolutional neural networks.” arXiv preprint arXiv:1604.01178 (2016).</a>では、質問文と回答文の最適な表現を学習するCNNを提案している。</p>
  </li>
</ol>

<h3 id="発話認識について">発話認識について</h3>

<ol>
  <li>
    <p><a href="http://newiranians.ir/TASLP2339736-proof.pdf">Abdel-Hamid, Ossama, et al. “Convolutional neural networks for speech recognition.” IEEE/ACM Transactions on audio, speech, and language processing 22.10 (2014): 1533-1545.</a>では、どのようにCNNを発話認識に適用するかが述べられている。ここではHMMとCNNのハイブリッド構造が示されている。</p>
  </li>
  <li>
    <p><a href="https://infoscience.epfl.ch/record/210039/files/Palaz_Idiap-RR-23-2015.pdf">Palaz, Dimitri, and Ronan Collobert. Analysis of cnn-based speech recognition system using raw speech as input. No. EPFL-REPORT-210039. Idiap, 2015.</a>では、最初の2層の畳み込み層でモデリングされた発話情報を理解するためにCNNを分析している。</p>
  </li>
  <li>
    <p><a href="https://pdfs.semanticscholar.org/528d/a8ef5cac3b69348b84a50ac2d596ddbee394.pdf">Song, William, and Jim Cai. End-to-end deep neural network for automatic speech recognition. Technical Report CS224D, University of Stanford, 2015.</a>では、mel-filter bank特徴量を利用して、従来の隠れマルコフモデルを必要としないEnd-to-EndなDeep Learningシステムを実装している。</p>
  </li>
  <li>
    <p><a href="https://www.researchgate.net/profile/Ossama_Abdel-Hamid/publication/261119155_Applying_Convolutional_Neural_Networks_concepts_to_hybrid_NN-HMM_model_for_speech_recognition/links/559407fd08ae5af2b0ecf4fb.pdf">Abdel-Hamid, Ossama, et al. “Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition.” Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on. IEEE, 2012.</a>では、NN-HMMモデルとCNNを合わせて発話認識を行うモデルを提案している。</p>
  </li>
</ol>

<h3 id="その他">その他</h3>

<ol>
  <li>
    <p><a href="https://arxiv.org/pdf/1504.06580">Santos, Cicero Nogueira dos, Bing Xiang, and Bowen Zhou. “Classifying relations by ranking with convolutional neural networks.” arXiv preprint arXiv:1504.06580 (2015).</a>では、Classification by Ranking CNN(CR=CNN)を用いて関係分類タスクに取り組んでいるものである。</p>
  </li>
  <li>
    <p><a href="http://anthology.aclweb.org/P/P15/P15-1151.pdf">Li, Mingxuan Wang1 Zhengdong Lu2 Hang, and Wenbin Jiang1 Qun Liu. “A convolutional architecture for word sequence prediction.” (2015).</a>では、条件付き確率をモデル化する目的で、言語の局所構造と広い範囲の構造を効率よく組み合わせるモデルとして、genCNNというCNNアーキテクチャを提案している。</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1404.2188.pdf?utm_content=bufferee286&amp;utm_medium=social&amp;utm_source=plus.google.com&amp;utm_campaign=buffer">Kalchbrenner, Nal, Edward Grefenstette, and Phil Blunsom. “A convolutional neural network for modelling sentences.” arXiv preprint arXiv:1404.2188 (2014).</a>では、文に対して意味論的モデリングを行うためのDynamic Convolutional Neural Network(DCNN)を提案している。このネットワークは可変長の文を扱うことができ、文において局所的・全域的な特徴を捉えることができる。</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/pdf/1603.03827">Lee, Ji Young, and Franck Dernoncourt. “Sequential short-text classification with recurrent and convolutional neural networks.” arXiv preprint arXiv:1603.03827 (2016).</a>では、短い文を組み込んだRNNとCNNに基づくモデルを提示している。</p>
  </li>
</ol>

<h2 id="4-議論はあるか">4. 議論はあるか？</h2>

<p>CNNはコンピュータビジョンの分野で成功を収めたことがきっかけでNLPの分野でも使われているのが主な問題の1つとして挙げられている。このために、「共通の目標」のようなものが欠けていると著者は感じているようだ。</p>

<h3 id="論文情報リンク">論文情報・リンク</h3>

<ul>
  <li><a href="https://arxiv.org/abs/1703.03091">Marc Moreno Lopez, Jugal Kalita. 2017. “Deep Learning applied to NLP.” arXiv preprint arXiv:1703.03091.</a></li>
</ul>

  </div>
  <div class="social-button-item">
  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-size="large" data-url="https://shunk031.github.io/paper-survey/summary/nlp/Deep-Learning-applied-to-NLP" data-via="shunk031" data-related="" data-show-count="false">Tweet</a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

<div class="social-button-item">
  <a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="basic-label-counter" data-hatena-bookmark-lang="ja" data-hatena-bookmark-height="28" title="このエントリーをはてなブックマークに追加">
    <img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" />
  </a><script type="text/javascript" src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
</div>

<div class="social-button-item">
  <div id="fb-root"></div>
  <script>(function(d, s, id) {
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) return;
     js = d.createElement(s); js.id = id;
     js.src = 'https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v3.1';
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));</script>

  <div class="fb-like" data-href="/summary/nlp/Deep-Learning-applied-to-NLP" data-layout="button_count" data-action="like" data-size="large" data-show-faces="true" data-share="true"></div>
</div>

</article>
<!-- Post Navigation -->
<div class="pagination">
  <a class="prev" href="/paper-survey/summary/cv/Learning-Deep-Classifiers-with-Deep-Features">←&nbsp; Previous post</a>
  <a class="next" href="/paper-survey/summary/nlp/Modelling-Visualising-and-Summarising-Documents-with-a-Single-Convolutional-Neural-Network">Next post&nbsp;→</a>
</div>

      </div>
    </div>
    <footer class="site-footer">
  <div class="wrapper">
    <span class="site-footer-owner">
      <a href="https://github.com/shunk031/paper-survey">Paper Survey</a> is maintained by <a href="https://github.com/shunk031">shunk031</a>.
    </span>
    <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
  </div>
</footer>

<amp-analytics type="googleanalytics" id="analytics1">
  <script type="application/json">
    {
	"vars": {
	    "account": "UA-114287158-1"
	},
	"triggers": {
	    "trackPageview": {
		"on": "visible",
		"request": "pageview"
	    }
	}
    }
  </script>
</amp-analytics>


<amp-install-serviceworker src="https://shunk031.github.io/paper-survey/sw.js" layout="nodisplay"></amp-install-serviceworker>

  </body>
</html>
